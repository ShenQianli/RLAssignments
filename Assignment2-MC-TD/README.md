

# Assignment 2: Random Walk

In this assignment, you are required to use Monte-Carlo (MC) and Temporal-Difference (TD) to estimate the values of 
states in a random walk example (see Lec 4 Page 19 for details)

### Requirement
You are required to complete ```try.py``` to reproduce the results showed in Lec 4 Page 19-20.
If you find it difficult, you can refer to ```run.py``` for inspiration.

### BONUS
(a) We choose discounted factor 1.0 for this task so TD([0,1]) are all equivalent. 
You can try to modify the discounted factor and sweep [0,1] for lambda, just like what we did for alpha, to see its 
impact on value estimation.
